[
  {
    "objectID": "forensicface.html",
    "href": "forensicface.html",
    "title": "forensicface–A tool for forensic face examination",
    "section": "",
    "text": "source"
  },
  {
    "objectID": "forensicface.html#comparação-entre-duas-imagens",
    "href": "forensicface.html#comparação-entre-duas-imagens",
    "title": "forensicface–A tool for forensic face examination",
    "section": "Comparação entre duas imagens",
    "text": "Comparação entre duas imagens\n\nsource\n\nForensicFace.compare\n\n ForensicFace.compare (img1path:str, img2path:str)\n\nCompares the similarity between two face images based on their embeddings.\nParameters: - img1path (str): Path to the first image file - img2path (str): Path to the second image file\nReturns: A float representing the similarity score between the two faces based on their embeddings. The score ranges from -1.0 to 1.0, where 1.0 represents a perfect match and -1.0 represents a complete mismatch.\n\nff.compare(\"obama.png\", \"obama2.png\")\n\n0.8555971"
  },
  {
    "objectID": "forensicface.html#agregação-de-embeddings",
    "href": "forensicface.html#agregação-de-embeddings",
    "title": "forensicface–A tool for forensic face examination",
    "section": "Agregação de embeddings",
    "text": "Agregação de embeddings\n\nsource\n\nForensicFace.aggregate_embeddings\n\n ForensicFace.aggregate_embeddings (embeddings, weights=None)\n\nAggregates multiple embeddings into a single embedding.\nArgs: embeddings (numpy.ndarray): A 2D array of shape (num_embeddings, embedding_dim) containing the embeddings to be aggregated. weights (numpy.ndarray, optional): A 1D array of shape (num_embeddings,) containing the weights to be assigned to each embedding. If not provided, all embeddings are equally weighted.\nReturns: numpy.ndarray: A 1D array of shape (embedding_dim,) containing the aggregated embedding.\n\nsource\n\n\nForensicFace.aggregate_from_images\n\n ForensicFace.aggregate_from_images (list_of_image_paths)\n\nGiven a list of image paths, this method returns the average embedding of all faces found in the images.\nArgs: list_of_image_paths (List[str]): List of paths to images.\nReturns: Union[np.ndarray, List]: If one or more faces are found, returns a 1D numpy array of shape (512,) representing the average embedding. Otherwise, returns an empty list.\n\naggregated = ff.aggregate_from_images([\"obama.png\", \"obama2.png\"])\naggregated.shape\n\n(512,)"
  },
  {
    "objectID": "forensicface.html#suporte-a-magface",
    "href": "forensicface.html#suporte-a-magface",
    "title": "forensicface–A tool for forensic face examination",
    "section": "Suporte a MagFace",
    "text": "Suporte a MagFace\nPara utilizar, instancie o forensicface com a opção magface = True:\nff = forensicface(magface=True)\nModelo de MagFace\n\nff = ForensicFace(det_size=320, use_gpu=True, magface=True)\ngood = ff.process_image(\"001_frontal.JPG\")\nbad = ff.process_image(\"001_cam1_1.jpg\")\ngood[\"magface_norm\"], bad[\"magface_norm\"]\n\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'arena_extend_strategy': 'kNextPowerOfTwo', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'cudnn_conv_use_max_workspace': '0', 'gpu_mem_limit': '18446744073709551615', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_alloc': '0', 'device_id': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'arena_extend_strategy': 'kNextPowerOfTwo', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'cudnn_conv_use_max_workspace': '0', 'gpu_mem_limit': '18446744073709551615', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_alloc': '0', 'device_id': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'arena_extend_strategy': 'kNextPowerOfTwo', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'cudnn_conv_use_max_workspace': '0', 'gpu_mem_limit': '18446744073709551615', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_alloc': '0', 'device_id': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\nset det-size: (320, 320)\n\n\n(23.233418, 22.57745)"
  },
  {
    "objectID": "forensicface.html#extração-de-faces-de-vídeos-com-margem",
    "href": "forensicface.html#extração-de-faces-de-vídeos-com-margem",
    "title": "forensicface–A tool for forensic face examination",
    "section": "Extração de faces de vídeos com margem",
    "text": "Extração de faces de vídeos com margem\n\nsource\n\nForensicFace.extract_faces\n\n ForensicFace.extract_faces (video_path:str, dest_folder:str=None,\n                             every_n_frames:int=1, margin:float=2.0,\n                             start_from:float=0.0)\n\nExtracts faces from a video and saves them as individual images.\nParameters: video_path (str): The path to the input video file. dest_folder (str, optional): The path to the output folder. If not provided, a new folder with the same name as the input video file is created. every_n_frames (int, optional): Extract faces from every n-th frame. Default is 1 (extract faces from all frames). margin (float, optional): The factor by which the detected face bounding box should be extended. Default is 2.0. start_from (float, optional): The time point (in seconds) after which the video frames should be processed. Default is 0.0.\nReturns: The number of extracted faces.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nvideo_path\nstr\n\npath to video file\n\n\ndest_folder\nstr\nNone\nfolder used to save extracted faces. If not provided, a new folder with the video name is created\n\n\nevery_n_frames\nint\n1\nskip some frames\n\n\nmargin\nfloat\n2.0\nmargin to add to each face, w.r.t. detected bounding box\n\n\nstart_from\nfloat\n0.0\nseconds after video start to begin processing\n\n\n\n\nff = ForensicFace()\n\n\nff.extract_faces(\n    video_path=\"/home/rafael/productionID_3762907.mp4\",\n    start_from=0,\n    every_n_frames=10,\n    dest_folder=\"/home/rafael/video_faces\",\n)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "forensicface",
    "section": "",
    "text": "pip install forensicface\nOs arquivos onnx dos modelos de detecção (det_10g.onnx), pose (1k3d68.onnx) e gênero/idade (genderage.onnx) devem estar na pasta ~/.insightface/model/sepaelv2/\nO arquivo onnx do modelo de reconhecimento (adaface_ir101web12m.onnx) deve estar na pasta ~/.insightface/model/sepaelv2/adaface/\nO arquivo onnx do modelo magface (magface_iresnet100.onnx) deve estar na pasta ~/.insightface/model/sepaelv2/magface/\nA partir da versão 0.1.5 é possível utilizar outros modelos além do sepaelv2"
  },
  {
    "objectID": "index.html#como-utilizar",
    "href": "index.html#como-utilizar",
    "title": "forensicface",
    "section": "Como utilizar",
    "text": "Como utilizar\nImportação da classe ForensicFace:\nfrom forensicface.app import ForensicFace\n\nff = ForensicFace(det_size=320, use_gpu=True)"
  },
  {
    "objectID": "index.html#processamento-básico-de-imagens",
    "href": "index.html#processamento-básico-de-imagens",
    "title": "forensicface",
    "section": "Processamento básico de imagens",
    "text": "Processamento básico de imagens\nObter pontos de referência, distância interpupilar, representação vetorial e a face alinhada com dimensão fixa (112x112)\n\nresults = ff.process_image_single_face(\"obama.png\")\nresults.keys()\n\ndict_keys(['keypoints', 'ipd', 'gender', 'age', 'pitch', 'yaw', 'roll', 'embedding', 'norm', 'magface_embedding', 'magface_norm', 'aligned_face'])\n\n\nComparar duas imagens faciais e obter o escore de similaridade.\n\nff.compare(\"obama.png\",\"obama2.png\")\n\n0.8555868\n\n\nAgregar embeddings de duas imagens faciais em uma única representação\n\nagg = ff.aggregate_from_images([\"obama.png\",\"obama2.png\"])\nagg.shape\n\n(512,)"
  },
  {
    "objectID": "index.html#suporte-a-magface",
    "href": "index.html#suporte-a-magface",
    "title": "forensicface",
    "section": "Suporte a MagFace",
    "text": "Suporte a MagFace\nEstimativa de qualidade pela norma da representação MagFace\nPara utilizar, instancie o forensicface com a opção magface = True:\nff = ForensicFace(magface=True)\n\nff = ForensicFace(det_size=320, use_gpu=True, magface=True)\ngood = ff.process_image(\"obama.png\")\nbad = ff.process_image(\"obama2.png\")\ngood[\"magface_norm\"], bad[\"magface_norm\"]\n\n(24.875765, 21.319853)"
  },
  {
    "objectID": "index.html#crédito-dos-modelos-utilizados",
    "href": "index.html#crédito-dos-modelos-utilizados",
    "title": "forensicface",
    "section": "Crédito dos modelos utilizados",
    "text": "Crédito dos modelos utilizados\n\nDetecção, gênero (M/F), idade e pose (pitch, yaw, roll): insightface\nReconhecimento: adaface e MagFace\nEstimativa de qualidade: MagFace"
  }
]