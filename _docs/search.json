[
  {
    "objectID": "utils.html",
    "href": "utils.html",
    "title": "Utilities",
    "section": "",
    "text": "source\n\ncosine_similarity\n\n cosine_similarity (X, Z)\n\n\nsource\n\n\ncompute_ss_ds\n\n compute_ss_ds (X, x_id, x_names=None, Z=None, z_id=None, z_names=None)\n\n*Compute cosine similarities between the cartesian product of two arrays X and Z and return same-source (ss) and different-source (ds) scores. If only the array X and x_id are provided, compute the cosine similarities between all pairwise combination in X. Also return the names of the files associated with each score, is x_names and z_names are provided.\nInputs: X, Z: 2d numpy arrays with embeddings (1 per line) x_id, z_id: 1d numpy arrays with identity labels x_names, z_names: 1d numpy arrays with names of files associated with the embeddings\nReturns: scores: 1d numpy array with scores y: 1d numpy arrays with ss (1) and ds (0) labels to the scores array names: list of tuples with names of files associated with each score*\n\n# Example usage\nX = np.random.rand(4, 128)  # 4 embeddings of dimension 128\nx_id = np.array([0, 0, 1, 1])  # Identity labels\nx_names = np.array([\"0_a.jpg\", \"0_b.jpg\", \"1_a.jpg\", \"1_b.jpg\"])\n\nZ = np.random.rand(4, 128)  # 4 embeddings of dimension 128\nz_id = np.array([0, 1, 1, 2])  # Identity labels\nz_names = np.array([\"0_c.jpg\", \"1_c.jpg\", \"1_d.jpg\", \"2_a.jpg\"])\n\nscores, y, names = compute_ss_ds(\n    X=X, x_id=x_id, x_names=x_names, Z=Z, z_id=z_id, z_names=z_names\n)\nscores, y, names\n\n(array([0.7261676 , 0.76134557, 0.78772832, 0.76922003, 0.74130075,\n        0.75798372, 0.77273163, 0.75997033, 0.76467846, 0.71801777,\n        0.75326126, 0.73211696, 0.72354578, 0.78339759, 0.74410164,\n        0.74325012]),\n array([1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n [('0_a.jpg', '0_c.jpg'),\n  ('0_b.jpg', '0_c.jpg'),\n  ('1_a.jpg', '1_c.jpg'),\n  ('1_a.jpg', '1_d.jpg'),\n  ('1_b.jpg', '1_c.jpg'),\n  ('1_b.jpg', '1_d.jpg'),\n  ('0_a.jpg', '1_c.jpg'),\n  ('0_a.jpg', '1_d.jpg'),\n  ('0_a.jpg', '2_a.jpg'),\n  ('0_b.jpg', '1_c.jpg'),\n  ('0_b.jpg', '1_d.jpg'),\n  ('0_b.jpg', '2_a.jpg'),\n  ('1_a.jpg', '0_c.jpg'),\n  ('1_a.jpg', '2_a.jpg'),\n  ('1_b.jpg', '0_c.jpg'),\n  ('1_b.jpg', '2_a.jpg')])\n\n\n\nscores, y, names = compute_ss_ds(X=X, x_id=x_id, Z=Z, z_id=z_id)\nscores, y, names\n\n(array([0.7261676 , 0.76134557, 0.78772832, 0.76922003, 0.74130075,\n        0.75798372, 0.77273163, 0.75997033, 0.76467846, 0.71801777,\n        0.75326126, 0.73211696, 0.72354578, 0.78339759, 0.74410164,\n        0.74325012]),\n array([1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n None)\n\n\n\nscores, y, names = compute_ss_ds(X=X, x_id=x_id, x_names=x_names)\nscores, y, names\n\n(array([0.75920622, 0.77365152, 0.76394119, 0.78708138, 0.75681996,\n        0.79128601]),\n array([1., 1., 0., 0., 0., 0.]),\n [('0_a.jpg', '0_b.jpg'),\n  ('1_a.jpg', '1_b.jpg'),\n  ('0_a.jpg', '1_a.jpg'),\n  ('0_a.jpg', '1_b.jpg'),\n  ('0_b.jpg', '1_a.jpg'),\n  ('0_b.jpg', '1_b.jpg')])\n\n\n\nscores, y, names = compute_ss_ds(X=X, x_id=x_id)\nscores, y, names\n\n(array([0.75920622, 0.77365152, 0.76394119, 0.78708138, 0.75681996,\n        0.79128601]),\n array([1., 1., 0., 0., 0., 0.]),\n None)\n\n\n\nExport the Python version and the packages names and versions in the active virtual environment\n\n\nsource\n\n\nfreeze_env\n\n freeze_env ()\n\n\n# example usage\n\nfreeze_env()\n\n{'Python version': '3.10.11 (main, May 16 2023, 00:28:57) [GCC 11.2.0]',\n 'albumentations': '1.3.1',\n 'asttokens': '2.2.1',\n 'astunparse': '1.6.3',\n 'backcall': '0.2.0',\n 'backports.functools-lru-cache': '1.6.4',\n 'bleach': '6.0.0',\n 'certifi': '2023.5.7',\n 'cffi': '1.15.1',\n 'charset-normalizer': '3.1.0',\n 'coloredlogs': '15.0.1',\n 'contourpy': '1.1.0',\n 'cryptography': '41.0.1',\n 'cycler': '0.11.0',\n 'Cython': '0.29.35',\n 'debugpy': '1.5.1',\n 'decorator': '5.1.1',\n 'docutils': '0.20.1',\n 'easydict': '1.10',\n 'entrypoints': '0.4',\n 'execnb': '0.1.5',\n 'executing': '1.2.0',\n 'fastcore': '1.5.29',\n 'flatbuffers': '23.5.26',\n 'fonttools': '4.40.0',\n 'forensicface': '0.3.5',\n 'ghapi': '1.0.4',\n 'humanfriendly': '10.0',\n 'idna': '3.4',\n 'imageio': '2.31.1',\n 'importlib-metadata': '6.7.0',\n 'imutils': '0.5.4',\n 'insightface': '0.7.3',\n 'ipykernel': '6.15.0',\n 'ipython': '8.14.0',\n 'jaraco.classes': '3.2.3',\n 'jedi': '0.18.2',\n 'jeepney': '0.8.0',\n 'joblib': '1.2.0',\n 'jupyter-client': '7.3.4',\n 'jupyter-core': '5.3.1',\n 'jupyterlab-quarto': '0.2.8',\n 'keyring': '24.0.0',\n 'kiwisolver': '1.4.4',\n 'lazy-loader': '0.2',\n 'markdown-it-py': '3.0.0',\n 'matplotlib': '3.7.1',\n 'matplotlib-inline': '0.1.6',\n 'mdurl': '0.1.2',\n 'more-itertools': '9.1.0',\n 'mpmath': '1.3.0',\n 'nbdev': '2.3.27',\n 'nest-asyncio': '1.5.6',\n 'networkx': '3.1',\n 'numpy': '1.25.0',\n 'onnx': '1.14.0',\n 'onnxruntime-gpu': '1.15.0',\n 'opencv-python-headless': '4.7.0.72',\n 'packaging': '23.1',\n 'pandas': '2.0.2',\n 'parso': '0.8.3',\n 'pexpect': '4.8.0',\n 'pickleshare': '0.7.5',\n 'Pillow': '9.5.0',\n 'pip': '23.1.2',\n 'pkginfo': '1.9.6',\n 'platformdirs': '3.6.0',\n 'prettytable': '3.8.0',\n 'prompt-toolkit': '3.0.38',\n 'protobuf': '4.23.3',\n 'psutil': '5.9.0',\n 'ptyprocess': '0.7.0',\n 'pure-eval': '0.2.2',\n 'pycparser': '2.21',\n 'Pygments': '2.15.1',\n 'pyparsing': '3.1.0',\n 'python-dateutil': '2.8.2',\n 'pytz': '2023.3',\n 'PyWavelets': '1.4.1',\n 'PyYAML': '6.0',\n 'pyzmq': '25.1.0',\n 'qudida': '0.0.4',\n 'readme-renderer': '40.0',\n 'requests': '2.31.0',\n 'requests-toolbelt': '1.0.0',\n 'rfc3986': '2.0.0',\n 'rich': '13.4.2',\n 'scikit-image': '0.21.0',\n 'scikit-learn': '1.2.2',\n 'scipy': '1.10.1',\n 'seaborn': '0.13.2',\n 'SecretStorage': '3.3.3',\n 'setuptools': '67.8.0',\n 'six': '1.16.0',\n 'stack-data': '0.6.2',\n 'sympy': '1.12',\n 'threadpoolctl': '3.1.0',\n 'tifffile': '2023.4.12',\n 'tornado': '6.1',\n 'tqdm': '4.65.0',\n 'traitlets': '5.9.0',\n 'twine': '4.0.2',\n 'typing-extensions': '4.6.3',\n 'tzdata': '2023.3',\n 'urllib3': '2.0.3',\n 'watchdog': '3.0.0',\n 'wcwidth': '0.2.6',\n 'webencodings': '0.5.1',\n 'wheel': '0.38.4',\n 'zipp': '3.15.0'}\n\n\n\nsource\n\n\ntransform_keypoints\n\n transform_keypoints (keypoints, M)\n\n*Transforms keypoints from the original image space to the aligned image space.\nArgs: keypoints (numpy array): A 2D array of shape (5, 2) representing the original keypoints. M (numpy array): The 2x3 affine transformation matrix.\nReturns: numpy array: A 2D array of shape (5, 2) representing the transformed keypoints.*\n\nsource\n\n\nannotate_img_with_kps\n\n annotate_img_with_kps (bgr_img:numpy.ndarray, kps:numpy.ndarray,\n                        color:str='red', radius:int=2)\n\n*Annotate an image with keypoints.\nParameters: bgr_img (numpy.ndarray): The input image in BGR format. kps (numpy.ndarray): A numpy array of shape (5, 2) containing the keypoints. color (str, optional): The color of the keypoints. Default is ‘red’. Options are ‘red’, ‘blue’, ‘green’, ‘white’, ‘black’. radius (int, optional): The radius of the keypoints. Default is 2.\nReturns: numpy.ndarray: The image with keypoints annotated.*",
    "crumbs": [
      "Utilities"
    ]
  },
  {
    "objectID": "forensicface.html",
    "href": "forensicface.html",
    "title": "forensicface–A tool for forensic face examination",
    "section": "",
    "text": "source",
    "crumbs": [
      "forensicface--A tool for forensic face examination"
    ]
  },
  {
    "objectID": "forensicface.html#comparação-entre-duas-imagens",
    "href": "forensicface.html#comparação-entre-duas-imagens",
    "title": "forensicface–A tool for forensic face examination",
    "section": "Comparação entre duas imagens",
    "text": "Comparação entre duas imagens\n\nsource\n\nForensicFace.compare\n\n ForensicFace.compare (img1path:str, img2path:str)\n\n*Compares the similarity between two face images based on their embeddings.\nParameters: - img1path (str): Path to the first image file - img2path (str): Path to the second image file\nReturns: A float representing the similarity score between the two faces based on their embeddings. The score ranges from -1.0 to 1.0, where 1.0 represents a perfect match and -1.0 represents a complete mismatch.*\n\nff.compare(\"obama.png\", \"obama2.png\")\n\n0.8556277",
    "crumbs": [
      "forensicface--A tool for forensic face examination"
    ]
  },
  {
    "objectID": "forensicface.html#agregação-de-embeddings",
    "href": "forensicface.html#agregação-de-embeddings",
    "title": "forensicface–A tool for forensic face examination",
    "section": "Agregação de embeddings",
    "text": "Agregação de embeddings\n\nsource\n\nForensicFace.aggregate_embeddings\n\n ForensicFace.aggregate_embeddings (embeddings, weights=None,\n                                    method='mean')\n\n*Aggregates multiple embeddings into a single embedding.\nArgs: embeddings (numpy.ndarray): A 2D array of shape (num_embeddings, embedding_dim) containing the embeddings to be aggregated. weights (numpy.ndarray, optional): A 1D array of shape (num_embeddings,) containing the weights to be assigned to each embedding. If not provided, all embeddings are equally weighted.\nmethod (str, optional): choice of agregating based on the mean or median of the embeddings. Possible values are\n    'mean' and 'median'.\nReturns: numpy.ndarray: A 1D array of shape (embedding_dim,) containing the aggregated embedding.*\n\nsource\n\n\nForensicFace.aggregate_from_images\n\n ForensicFace.aggregate_from_images (list_of_image_paths, method='mean',\n                                     quality_weight=False)\n\n*Given a list of image paths, this method returns the average embedding of all faces found in the images.\nArgs: list_of_image_paths (List[str]): List of paths to images. method (str, optional): choice of agregating based on the mean or median of the embeddings. Possible values are ‘mean’ and ‘median’. quality_weight (boolean, optional): If True, use the FIQA(L) score as a weight for aggregation.\nReturns: Union[np.ndarray, List]: If one or more faces are found, returns a 1D numpy array of shape (512,) representing the average embedding. Otherwise, returns an empty list.*\n\nff = ForensicFace(extended=True)\n\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\nset det-size: (320, 320)\n\n\n\naggregated = ff.aggregate_from_images([\"obama.png\", \"obama2.png\"], quality_weight=True)\naggregated.shape\n\n(512,)",
    "crumbs": [
      "forensicface--A tool for forensic face examination"
    ]
  },
  {
    "objectID": "forensicface.html#extração-de-faces-de-vídeos-com-margem",
    "href": "forensicface.html#extração-de-faces-de-vídeos-com-margem",
    "title": "forensicface–A tool for forensic face examination",
    "section": "Extração de faces de vídeos com margem",
    "text": "Extração de faces de vídeos com margem\n\nsource\n\nForensicFace.extract_faces\n\n ForensicFace.extract_faces (video_path:str, dest_folder:str=None,\n                             every_n_frames:int=1, margin:float=2.0,\n                             start_from:float=0.0,\n                             export_metadata:bool=False)\n\n*Extracts faces from a video and saves them as individual images.\nParameters: video_path (str): The path to the input video file. dest_folder (str, optional): The path to the output folder. If not provided, a new folder with the same name as the input video file is created. every_n_frames (int, optional): Extract faces from every n-th frame. Default is 1 (extract faces from all frames). margin (float, optional): The factor by which the detected face bounding box should be extended. Default is 2.0. start_from (float, optional): The time point (in seconds) after which the video frames should be processed. Default is 0.0.\nReturns: The number of extracted faces.*\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\nvideo_path\nstr\n\npath to video file\n\n\ndest_folder\nstr\nNone\nfolder used to save extracted faces. If not provided, a new folder with the video name is created\n\n\nevery_n_frames\nint\n1\nskip some frames\n\n\nmargin\nfloat\n2.0\nmargin to add to each face, w.r.t. detected bounding box\n\n\nstart_from\nfloat\n0.0\nseconds after video start to begin processing\n\n\nexport_metadata\nbool\nFalse\nif True, export facial keypoints, bounding box, ipd, fiqa_score, pitch, yaw, roll, and embedding\n\n\n\n\nff = ForensicFace()\n\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\nset det-size: (320, 320)\n\n\n\nff.extract_faces(\n    video_path=\"/home/rafael/video/video.mp4\",\n    start_from=0,\n    every_n_frames=600,\n    dest_folder=\"/home/rafael/video_faces\",\n    export_metadata=True,\n)\n\nFrames processed: 0/14 | Time elapsed: 00:00Frames processed: 14/14 | Time elapsed: 00:53\n\n\n12",
    "crumbs": [
      "forensicface--A tool for forensic face examination"
    ]
  },
  {
    "objectID": "forensicface.html#processing-aligned-images",
    "href": "forensicface.html#processing-aligned-images",
    "title": "forensicface–A tool for forensic face examination",
    "section": "Processing aligned images",
    "text": "Processing aligned images\n\nsource\n\nForensicFace.process_aligned_face_image\n\n ForensicFace.process_aligned_face_image (rgb_aligned_face:numpy.ndarray)\n\n\nff = ForensicFace(extended=True, models=[\"sepaelv2\", \"sepaelv4\"])\n\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\nset det-size: (320, 320)\n\n\n\nret = ff.process_image_single_face(\"obama.png\")\nret2 = ff.process_aligned_face_image(ret[\"aligned_face\"])\n\n/home/rafael/miniconda3/envs/ffdev/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n\n\n\nnp.allclose(ret[\"embedding\"], ret2[\"embedding\"])\n\nTrue\n\n\n\nret[\"fiqa_score\"], ret2[\"fiqa_score\"]\n\n(2.1983922, 2.1983922)",
    "crumbs": [
      "forensicface--A tool for forensic face examination"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "forensicface",
    "section": "",
    "text": "pip install forensicface\nOs arquivos onnx dos modelos de detecção (det_10g.onnx), pose (1k3d68.onnx) e gênero/idade (genderage.onnx) devem estar na pasta ~/.insightface/model/&lt;model_name&gt;/\nO arquivo onnx do modelo de reconhecimento (adaface_ir101web12m.onnx) deve estar na pasta ~/.insightface/model/&lt;model_name&gt;/adaface/\nO arquivo onnx do modelo de qualidade CR_FIQA (cr_fiqa_l.onnx) deve estar na pasta ~/.insightface/model/&lt;model_name&gt;/cr_fiqa/\nO modelo padrão é denominado sepaelv2. A partir da versão 0.1.5 é possível utilizar outros modelos.",
    "crumbs": [
      "forensicface"
    ]
  },
  {
    "objectID": "index.html#install",
    "href": "index.html#install",
    "title": "forensicface",
    "section": "",
    "text": "pip install forensicface\nOs arquivos onnx dos modelos de detecção (det_10g.onnx), pose (1k3d68.onnx) e gênero/idade (genderage.onnx) devem estar na pasta ~/.insightface/model/&lt;model_name&gt;/\nO arquivo onnx do modelo de reconhecimento (adaface_ir101web12m.onnx) deve estar na pasta ~/.insightface/model/&lt;model_name&gt;/adaface/\nO arquivo onnx do modelo de qualidade CR_FIQA (cr_fiqa_l.onnx) deve estar na pasta ~/.insightface/model/&lt;model_name&gt;/cr_fiqa/\nO modelo padrão é denominado sepaelv2. A partir da versão 0.1.5 é possível utilizar outros modelos.",
    "crumbs": [
      "forensicface"
    ]
  },
  {
    "objectID": "index.html#como-utilizar",
    "href": "index.html#como-utilizar",
    "title": "forensicface",
    "section": "Como utilizar",
    "text": "Como utilizar\nImportação da classe ForensicFace:\n\nfrom forensicface.app import ForensicFace\n\nInstanciamento do ForensicFace:\n\nff = ForensicFace(det_size=320, use_gpu=True, extended=True)\n\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\nfind model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\nset det-size: (320, 320)",
    "crumbs": [
      "forensicface"
    ]
  },
  {
    "objectID": "index.html#processamento-básico-de-imagens",
    "href": "index.html#processamento-básico-de-imagens",
    "title": "forensicface",
    "section": "Processamento básico de imagens",
    "text": "Processamento básico de imagens\nObter pontos de referência, distância interpupilar, representação vetorial, a face alinhada com dimensão fixa (112x112), estimativas de sexo, idade, pose (pitch, yaw, roll) e qualidade. Opcionalmente, é possível anotar a face alinhada com os pontos de referência utilizados no alinhamento (parâmetro draw_kypoints).\n\nresults = ff.process_image_single_face(\"obama2.png\", draw_keypoints=True)\nresults.keys()\n\n/home/rafael/miniconda3/envs/ffdev/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n\n\ndict_keys(['keypoints', 'ipd', 'embedding', 'norm', 'bbox', 'det_score', 'aligned_face', 'gender', 'age', 'pitch', 'yaw', 'roll', 'fiqa_score'])\n\n\n\nplt.imshow(results[\"aligned_face\"])\n\n\n\n\n\n\n\n\nComparar duas imagens faciais e obter o escore de similaridade.\n\nff.compare(\"obama.png\", \"obama2.png\")\n\n0.8556093\n\n\nAgregar embeddings de duas imagens faciais em uma única representação, com ponderação por qualidade\n\nagg = ff.aggregate_from_images([\"obama.png\", \"obama2.png\"], quality_weight=True)\nagg.shape\n\n(512,)",
    "crumbs": [
      "forensicface"
    ]
  },
  {
    "objectID": "index.html#estimativa-de-qualidade-cr-fiqa",
    "href": "index.html#estimativa-de-qualidade-cr-fiqa",
    "title": "forensicface",
    "section": "Estimativa de qualidade CR-FIQA",
    "text": "Estimativa de qualidade CR-FIQA\nEstimativa de qualidade pelo método CR-FIQA\nPara desabilitar, instancie o forensicface com a opção extended = False:\nff = ForensicFace(extended=False)\nObs.: a opção extended = False também desabilita as estimativas de sexo, idade e pose.\n\ngood = ff.process_image(\"001_frontal.jpg\")\nbad = ff.process_image(\"001_cam1_1.jpg\")\ngood[\"fiqa_score\"], bad[\"fiqa_score\"]\n\n(2.3786173, 1.4386057)",
    "crumbs": [
      "forensicface"
    ]
  },
  {
    "objectID": "index.html#crédito-dos-modelos-utilizados",
    "href": "index.html#crédito-dos-modelos-utilizados",
    "title": "forensicface",
    "section": "Crédito dos modelos utilizados",
    "text": "Crédito dos modelos utilizados\n\nDetecção, gênero (M/F), idade e pose (pitch, yaw, roll): insightface\nReconhecimento: adaface\nEstimativa de qualidade: CR-FIQA",
    "crumbs": [
      "forensicface"
    ]
  }
]