{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: An integrated tool to compare faces using state-of-the-art face recognition\n",
    "  models and compute Likelihood Ratios\n",
    "output-file: forensicface.html\n",
    "title: forensicface--A tool for forensic face examination\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/forensicface.py#L7){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace\n",
       "\n",
       ">      ForensicFace (model:str='sepaelv2', det_size:int=320, use_gpu:bool=True,\n",
       ">                    gpu:int=0, magface=False, extended=True)\n",
       "\n",
       "Class for processing facial images to extract useful features for forensic analysis.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | str | sepaelv2 |  |\n",
       "| det_size | int | 320 |  |\n",
       "| use_gpu | bool | True |  |\n",
       "| gpu | int | 0 | which GPU to use |\n",
       "| magface | bool | False |  |\n",
       "| extended | bool | True |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/forensicface.py#L7){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace\n",
       "\n",
       ">      ForensicFace (model:str='sepaelv2', det_size:int=320, use_gpu:bool=True,\n",
       ">                    gpu:int=0, magface=False, extended=True)\n",
       "\n",
       "Class for processing facial images to extract useful features for forensic analysis.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| model | str | sepaelv2 |  |\n",
       "| det_size | int | 320 |  |\n",
       "| use_gpu | bool | True |  |\n",
       "| gpu | int | 0 | which GPU to use |\n",
       "| magface | bool | False |  |\n",
       "| extended | bool | True |  |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'arena_extend_strategy': 'kNextPowerOfTwo', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'cudnn_conv_use_max_workspace': '0', 'gpu_mem_limit': '18446744073709551615', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_alloc': '0', 'device_id': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'arena_extend_strategy': 'kNextPowerOfTwo', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'cudnn_conv_use_max_workspace': '0', 'gpu_mem_limit': '18446744073709551615', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_alloc': '0', 'device_id': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'arena_extend_strategy': 'kNextPowerOfTwo', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'cudnn_conv_use_max_workspace': '0', 'gpu_mem_limit': '18446744073709551615', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_alloc': '0', 'device_id': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "set det-size: (320, 320)\n"
     ]
    }
   ],
   "source": [
    "ff = ForensicFace(use_gpu=True, magface=False, extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "ff.process_image_single_face(\"001_frontal.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['keypoints', 'ipd', 'embedding', 'norm', 'bbox', 'aligned_face', 'gender', 'age', 'pitch', 'yaw', 'roll', 'fiqa_score']),\n",
       " array([[471.42807, 418.60446],\n",
       "        [522.6901 , 418.05377],\n",
       "        [498.82306, 449.08896],\n",
       "        [479.34985, 476.44186],\n",
       "        [514.3342 , 476.06934]], dtype=float32),\n",
       " array([441, 355, 548, 506]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = ff.process_image_multiple_faces(\"tela.png\")\n",
    "results[0].keys(), results[0][\"keypoints\"], results[0][\"bbox\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['keypoints', 'ipd', 'embedding', 'norm', 'bbox', 'aligned_face', 'gender', 'age', 'pitch', 'yaw', 'roll']),\n",
       " array([[103.60011, 139.88237],\n",
       "        [174.2651 , 137.3372 ],\n",
       "        [140.28094, 187.14757],\n",
       "        [109.09432, 219.3402 ],\n",
       "        [173.40782, 217.09576]], dtype=float32))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = ff.process_image_single_face(\"obama.png\")\n",
    "results.keys(), results[\"keypoints\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação entre duas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L405){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.compare\n",
       "\n",
       ">      ForensicFace.compare (img1path:str, img2path:str)\n",
       "\n",
       "Compares the similarity between two face images based on their embeddings.\n",
       "\n",
       "Parameters:\n",
       "    - img1path (str): Path to the first image file\n",
       "    - img2path (str): Path to the second image file\n",
       "\n",
       "Returns:\n",
       "    A float representing the similarity score between the two faces based on their embeddings.\n",
       "    The score ranges from -1.0 to 1.0, where 1.0 represents a perfect match and -1.0 represents a complete mismatch."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L405){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.compare\n",
       "\n",
       ">      ForensicFace.compare (img1path:str, img2path:str)\n",
       "\n",
       "Compares the similarity between two face images based on their embeddings.\n",
       "\n",
       "Parameters:\n",
       "    - img1path (str): Path to the first image file\n",
       "    - img2path (str): Path to the second image file\n",
       "\n",
       "Returns:\n",
       "    A float representing the similarity score between the two faces based on their embeddings.\n",
       "    The score ranges from -1.0 to 1.0, where 1.0 represents a perfect match and -1.0 represents a complete mismatch."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace.compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8555971"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.compare(\"obama.png\", \"obama2.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregação de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L428){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.aggregate_embeddings\n",
       "\n",
       ">      ForensicFace.aggregate_embeddings (embeddings, weights=None)\n",
       "\n",
       "Aggregates multiple embeddings into a single embedding.\n",
       "\n",
       "Args:\n",
       "    embeddings (numpy.ndarray): A 2D array of shape (num_embeddings, embedding_dim) containing the embeddings to be\n",
       "        aggregated.\n",
       "    weights (numpy.ndarray, optional): A 1D array of shape (num_embeddings,) containing the weights to be assigned\n",
       "        to each embedding. If not provided, all embeddings are equally weighted.\n",
       "\n",
       "Returns:\n",
       "    numpy.ndarray: A 1D array of shape (embedding_dim,) containing the aggregated embedding."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L428){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.aggregate_embeddings\n",
       "\n",
       ">      ForensicFace.aggregate_embeddings (embeddings, weights=None)\n",
       "\n",
       "Aggregates multiple embeddings into a single embedding.\n",
       "\n",
       "Args:\n",
       "    embeddings (numpy.ndarray): A 2D array of shape (num_embeddings, embedding_dim) containing the embeddings to be\n",
       "        aggregated.\n",
       "    weights (numpy.ndarray, optional): A 1D array of shape (num_embeddings,) containing the weights to be assigned\n",
       "        to each embedding. If not provided, all embeddings are equally weighted.\n",
       "\n",
       "Returns:\n",
       "    numpy.ndarray: A 1D array of shape (embedding_dim,) containing the aggregated embedding."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace.aggregate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L449){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.aggregate_from_images\n",
       "\n",
       ">      ForensicFace.aggregate_from_images (list_of_image_paths)\n",
       "\n",
       "Given a list of image paths, this method returns the average embedding of all faces found in the images.\n",
       "\n",
       "Args:\n",
       "    list_of_image_paths (List[str]): List of paths to images.\n",
       "\n",
       "Returns:\n",
       "    Union[np.ndarray, List]: If one or more faces are found, returns a 1D numpy array of shape (512,) representing the\n",
       "    average embedding. Otherwise, returns an empty list."
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L449){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.aggregate_from_images\n",
       "\n",
       ">      ForensicFace.aggregate_from_images (list_of_image_paths)\n",
       "\n",
       "Given a list of image paths, this method returns the average embedding of all faces found in the images.\n",
       "\n",
       "Args:\n",
       "    list_of_image_paths (List[str]): List of paths to images.\n",
       "\n",
       "Returns:\n",
       "    Union[np.ndarray, List]: If one or more faces are found, returns a 1D numpy array of shape (512,) representing the\n",
       "    average embedding. Otherwise, returns an empty list."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace.aggregate_from_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated = ff.aggregate_from_images([\"obama.png\", \"obama2.png\"])\n",
    "aggregated.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suporte a MagFace\n",
    "\n",
    "Para utilizar, instancie o forensicface com a opção magface = True:\n",
    "\n",
    "``ff = forensicface(magface=True)``\n",
    "\n",
    "Modelo de [MagFace](https://github.com/IrvingMeng/MagFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'arena_extend_strategy': 'kNextPowerOfTwo', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'cudnn_conv_use_max_workspace': '0', 'gpu_mem_limit': '18446744073709551615', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_alloc': '0', 'device_id': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'arena_extend_strategy': 'kNextPowerOfTwo', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'cudnn_conv_use_max_workspace': '0', 'gpu_mem_limit': '18446744073709551615', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_alloc': '0', 'device_id': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'do_copy_in_default_stream': '1', 'arena_extend_strategy': 'kNextPowerOfTwo', 'gpu_external_empty_cache': '0', 'gpu_external_free': '0', 'cudnn_conv_use_max_workspace': '0', 'gpu_mem_limit': '18446744073709551615', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'gpu_external_alloc': '0', 'device_id': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "set det-size: (320, 320)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23.233418, 22.57745)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff = ForensicFace(det_size=320, use_gpu=True, magface=True)\n",
    "good = ff.process_image(\"001_frontal.JPG\")\n",
    "bad = ff.process_image(\"001_cam1_1.jpg\")\n",
    "good[\"magface_norm\"], bad[\"magface_norm\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de faces de vídeos com margem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L510){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.extract_faces\n",
       "\n",
       ">      ForensicFace.extract_faces (video_path:str, dest_folder:str=None,\n",
       ">                                  every_n_frames:int=1, margin:float=2.0,\n",
       ">                                  start_from:float=0.0)\n",
       "\n",
       "Extracts faces from a video and saves them as individual images.\n",
       "\n",
       "Parameters:\n",
       "    video_path (str): The path to the input video file.\n",
       "    dest_folder (str, optional): The path to the output folder. If not provided, a new folder with the same name as the input video file is created.\n",
       "    every_n_frames (int, optional): Extract faces from every n-th frame. Default is 1 (extract faces from all frames).\n",
       "    margin (float, optional): The factor by which the detected face bounding box should be extended. Default is 2.0.\n",
       "    start_from (float, optional): The time point (in seconds) after which the video frames should be processed. Default is 0.0.\n",
       "\n",
       "Returns:\n",
       "    The number of extracted faces.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| video_path | str |  | path to video file |\n",
       "| dest_folder | str | None | folder used to save extracted faces. If not provided, a new folder with the video name is created |\n",
       "| every_n_frames | int | 1 | skip some frames |\n",
       "| margin | float | 2.0 | margin to add to each face, w.r.t. detected bounding box |\n",
       "| start_from | float | 0.0 | seconds after video start to begin processing |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L510){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.extract_faces\n",
       "\n",
       ">      ForensicFace.extract_faces (video_path:str, dest_folder:str=None,\n",
       ">                                  every_n_frames:int=1, margin:float=2.0,\n",
       ">                                  start_from:float=0.0)\n",
       "\n",
       "Extracts faces from a video and saves them as individual images.\n",
       "\n",
       "Parameters:\n",
       "    video_path (str): The path to the input video file.\n",
       "    dest_folder (str, optional): The path to the output folder. If not provided, a new folder with the same name as the input video file is created.\n",
       "    every_n_frames (int, optional): Extract faces from every n-th frame. Default is 1 (extract faces from all frames).\n",
       "    margin (float, optional): The factor by which the detected face bounding box should be extended. Default is 2.0.\n",
       "    start_from (float, optional): The time point (in seconds) after which the video frames should be processed. Default is 0.0.\n",
       "\n",
       "Returns:\n",
       "    The number of extracted faces.\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| video_path | str |  | path to video file |\n",
       "| dest_folder | str | None | folder used to save extracted faces. If not provided, a new folder with the video name is created |\n",
       "| every_n_frames | int | 1 | skip some frames |\n",
       "| margin | float | 2.0 | margin to add to each face, w.r.t. detected bounding box |\n",
       "| start_from | float | 0.0 | seconds after video start to begin processing |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace.extract_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "ff = ForensicFace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [],
   "source": [
    "ff.extract_faces(\n",
    "    video_path=\"/home/rafael/productionID_3762907.mp4\",\n",
    "    start_from=0,\n",
    "    every_n_frames=10,\n",
    "    dest_folder=\"/home/rafael/video_faces\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnxgpu",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
