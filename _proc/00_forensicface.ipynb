{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: An integrated tool to compare faces using state-of-the-art face recognition\n",
    "  models and compute Likelihood Ratios\n",
    "output-file: forensicface.html\n",
    "title: forensicface--A tool for forensic face examination\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/forensicface.py#L7){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace\n",
       "\n",
       ">      ForensicFace (models:list[str]=['sepaelv2'], model:str=None,\n",
       ">                    det_size:int=320, use_gpu:bool=True, gpu:int=0,\n",
       ">                    concat_embeddings:bool=True, extended=True,\n",
       ">                    det_thresh:float=0.5)\n",
       "\n",
       "*Class for processing facial images to extract useful features for forensic analysis.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| models | list | ['sepaelv2'] |  |\n",
       "| model | str | None |  |\n",
       "| det_size | int | 320 |  |\n",
       "| use_gpu | bool | True |  |\n",
       "| gpu | int | 0 | which GPU to use |\n",
       "| concat_embeddings | bool | True |  |\n",
       "| extended | bool | True |  |\n",
       "| det_thresh | float | 0.5 |  |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/forensicface.py#L7){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace\n",
       "\n",
       ">      ForensicFace (models:list[str]=['sepaelv2'], model:str=None,\n",
       ">                    det_size:int=320, use_gpu:bool=True, gpu:int=0,\n",
       ">                    concat_embeddings:bool=True, extended=True,\n",
       ">                    det_thresh:float=0.5)\n",
       "\n",
       "*Class for processing facial images to extract useful features for forensic analysis.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| models | list | ['sepaelv2'] |  |\n",
       "| model | str | None |  |\n",
       "| det_size | int | 320 |  |\n",
       "| use_gpu | bool | True |  |\n",
       "| gpu | int | 0 | which GPU to use |\n",
       "| concat_embeddings | bool | True |  |\n",
       "| extended | bool | True |  |\n",
       "| det_thresh | float | 0.5 |  |"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "set det-size: (320, 320)\n"
     ]
    }
   ],
   "source": [
    "ff = ForensicFace(\n",
    "    use_gpu=True,\n",
    "    extended=True,\n",
    "    det_thresh=0.5,\n",
    "    models=[\"sepaelv2\", \"sepaelv4\"],\n",
    "    concat_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<onnxruntime.capi.onnxruntime_inference_collection.InferenceSession>,\n",
       " <onnxruntime.capi.onnxruntime_inference_collection.InferenceSession>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.rec_inference_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['keypoints', 'ipd', 'embedding', 'bbox', 'det_score', 'aligned_face', 'gender', 'age', 'pitch', 'yaw', 'roll', 'fiqa_score'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = ff.process_image_single_face(\"obama.png\")\n",
    "ret.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/miniconda3/envs/ffdev/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8,\n",
       " dict_keys(['keypoints', 'ipd', 'embedding', 'bbox', 'det_score', 'aligned_face', 'gender', 'age', 'pitch', 'yaw', 'roll', 'fiqa_score']),\n",
       " dict_keys(['keypoints', 'ipd', 'embedding', 'bbox', 'det_score', 'aligned_face', 'gender', 'age', 'pitch', 'yaw', 'roll', 'fiqa_score']))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = ff.process_image_multiple_faces(\"tela.png\")\n",
    "len(ret), ret[0].keys(), ret[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[1][\"embedding\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "set det-size: (320, 320)\n"
     ]
    }
   ],
   "source": [
    "ff = ForensicFace(\n",
    "    use_gpu=True,\n",
    "    extended=True,\n",
    "    det_thresh=0.5,\n",
    "    models=[\"sepaelv2\"],\n",
    "    concat_embeddings=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/miniconda3/envs/ffdev/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_keys(['keypoints', 'ipd', 'embedding', 'bbox', 'det_score', 'aligned_face', 'gender', 'age', 'pitch', 'yaw', 'roll', 'fiqa_score'])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret = ff.process_image_single_face(\"obama.png\")\n",
    "ret.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[\"embedding\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Python version': '3.10.11 (main, May 16 2023, 00:28:57) [GCC 11.2.0]',\n",
       " 'albumentations': '1.3.1',\n",
       " 'asttokens': '2.2.1',\n",
       " 'astunparse': '1.6.3',\n",
       " 'backcall': '0.2.0',\n",
       " 'backports.functools-lru-cache': '1.6.4',\n",
       " 'bleach': '6.0.0',\n",
       " 'certifi': '2023.5.7',\n",
       " 'cffi': '1.15.1',\n",
       " 'charset-normalizer': '3.1.0',\n",
       " 'coloredlogs': '15.0.1',\n",
       " 'contourpy': '1.1.0',\n",
       " 'cryptography': '41.0.1',\n",
       " 'cycler': '0.11.0',\n",
       " 'Cython': '0.29.35',\n",
       " 'debugpy': '1.5.1',\n",
       " 'decorator': '5.1.1',\n",
       " 'docutils': '0.20.1',\n",
       " 'easydict': '1.10',\n",
       " 'entrypoints': '0.4',\n",
       " 'execnb': '0.1.5',\n",
       " 'executing': '1.2.0',\n",
       " 'fastcore': '1.5.29',\n",
       " 'flatbuffers': '23.5.26',\n",
       " 'fonttools': '4.40.0',\n",
       " 'forensicface': '0.3.6',\n",
       " 'ghapi': '1.0.4',\n",
       " 'humanfriendly': '10.0',\n",
       " 'idna': '3.4',\n",
       " 'imageio': '2.31.1',\n",
       " 'importlib-metadata': '6.7.0',\n",
       " 'imutils': '0.5.4',\n",
       " 'insightface': '0.7.3',\n",
       " 'ipykernel': '6.15.0',\n",
       " 'ipython': '8.14.0',\n",
       " 'jaraco.classes': '3.2.3',\n",
       " 'jedi': '0.18.2',\n",
       " 'jeepney': '0.8.0',\n",
       " 'joblib': '1.2.0',\n",
       " 'jupyter-client': '7.3.4',\n",
       " 'jupyter-core': '5.3.1',\n",
       " 'jupyterlab-quarto': '0.2.8',\n",
       " 'keyring': '24.0.0',\n",
       " 'kiwisolver': '1.4.4',\n",
       " 'lazy-loader': '0.2',\n",
       " 'markdown-it-py': '3.0.0',\n",
       " 'matplotlib': '3.7.1',\n",
       " 'matplotlib-inline': '0.1.6',\n",
       " 'mdurl': '0.1.2',\n",
       " 'more-itertools': '9.1.0',\n",
       " 'mpmath': '1.3.0',\n",
       " 'nbdev': '2.3.27',\n",
       " 'nest-asyncio': '1.5.6',\n",
       " 'networkx': '3.1',\n",
       " 'numpy': '1.25.0',\n",
       " 'onnx': '1.14.0',\n",
       " 'onnxruntime-gpu': '1.15.0',\n",
       " 'opencv-python-headless': '4.7.0.72',\n",
       " 'packaging': '23.1',\n",
       " 'pandas': '2.0.2',\n",
       " 'parso': '0.8.3',\n",
       " 'pexpect': '4.8.0',\n",
       " 'pickleshare': '0.7.5',\n",
       " 'Pillow': '9.5.0',\n",
       " 'pip': '23.1.2',\n",
       " 'pkginfo': '1.9.6',\n",
       " 'platformdirs': '3.6.0',\n",
       " 'prettytable': '3.8.0',\n",
       " 'prompt-toolkit': '3.0.38',\n",
       " 'protobuf': '4.23.3',\n",
       " 'psutil': '5.9.0',\n",
       " 'ptyprocess': '0.7.0',\n",
       " 'pure-eval': '0.2.2',\n",
       " 'pycparser': '2.21',\n",
       " 'Pygments': '2.15.1',\n",
       " 'pyparsing': '3.1.0',\n",
       " 'python-dateutil': '2.8.2',\n",
       " 'pytz': '2023.3',\n",
       " 'PyWavelets': '1.4.1',\n",
       " 'PyYAML': '6.0',\n",
       " 'pyzmq': '25.1.0',\n",
       " 'qudida': '0.0.4',\n",
       " 'readme-renderer': '40.0',\n",
       " 'requests': '2.31.0',\n",
       " 'requests-toolbelt': '1.0.0',\n",
       " 'rfc3986': '2.0.0',\n",
       " 'rich': '13.4.2',\n",
       " 'scikit-image': '0.21.0',\n",
       " 'scikit-learn': '1.2.2',\n",
       " 'scipy': '1.10.1',\n",
       " 'seaborn': '0.13.2',\n",
       " 'SecretStorage': '3.3.3',\n",
       " 'setuptools': '67.8.0',\n",
       " 'six': '1.16.0',\n",
       " 'stack-data': '0.6.2',\n",
       " 'sympy': '1.12',\n",
       " 'threadpoolctl': '3.1.0',\n",
       " 'tifffile': '2023.4.12',\n",
       " 'tornado': '6.1',\n",
       " 'tqdm': '4.65.0',\n",
       " 'traitlets': '5.9.0',\n",
       " 'twine': '4.0.2',\n",
       " 'typing-extensions': '4.6.3',\n",
       " 'tzdata': '2023.3',\n",
       " 'urllib3': '2.0.3',\n",
       " 'watchdog': '3.0.0',\n",
       " 'wcwidth': '0.2.6',\n",
       " 'webencodings': '0.5.1',\n",
       " 'wheel': '0.38.4',\n",
       " 'zipp': '3.15.0'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['keypoints', 'ipd', 'embedding', 'norm', 'bbox', 'det_score', 'aligned_face', 'gender', 'age', 'pitch', 'yaw', 'roll', 'fiqa_score']),\n",
       " array([[ 61.428093,  87.567154],\n",
       "        [103.14688 ,  97.62415 ],\n",
       "        [ 61.404076, 114.31358 ],\n",
       "        [ 50.038876, 143.41814 ],\n",
       "        [ 82.59338 , 152.32835 ]], dtype=float32),\n",
       " 42.91387,\n",
       " (512,),\n",
       " 0.83124155)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = ff.process_image_single_face(\"obama2.png\", draw_keypoints=True)\n",
    "result.keys(), result[\"keypoints\"], result[\"ipd\"], result[\"embedding\"].shape, result[\n",
    "    \"det_score\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: list of arrays passed as argument. Make sure image arrays are in BGR format.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(118, 236, 3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs = [cv2.imread(x) for x in [\"001_cam1_1.jpg\", \"001_frontal.jpg\"]]\n",
    "mosaic = ff.build_mosaic(imgs, mosaic_shape=(2, 1))\n",
    "mosaic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/miniconda3/envs/ffdev/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(dict_keys(['keypoints', 'ipd', 'embedding', 'norm', 'bbox', 'det_score', 'aligned_face', 'gender', 'age', 'pitch', 'yaw', 'roll', 'fiqa_score']),\n",
       " array([[471.42743, 418.60498],\n",
       "        [522.68933, 418.05362],\n",
       "        [498.82196, 449.08923],\n",
       "        [479.3499 , 476.44193],\n",
       "        [514.33453, 476.06885]], dtype=float32),\n",
       " array([441, 355, 548, 506]),\n",
       " 0.8962144)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = ff.process_image_multiple_faces(\"tela.png\", draw_keypoints=True)\n",
    "results[0].keys(), results[0][\"keypoints\"], results[0][\"bbox\"], results[0][\"det_score\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparação entre duas imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L502){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.compare\n",
       "\n",
       ">      ForensicFace.compare (img1path:str, img2path:str)\n",
       "\n",
       "*Compares the similarity between two face images based on their embeddings.\n",
       "\n",
       "Parameters:\n",
       "    - img1path (str): Path to the first image file\n",
       "    - img2path (str): Path to the second image file\n",
       "\n",
       "Returns:\n",
       "    A float representing the similarity score between the two faces based on their embeddings.\n",
       "    The score ranges from -1.0 to 1.0, where 1.0 represents a perfect match and -1.0 represents a complete mismatch.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L502){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.compare\n",
       "\n",
       ">      ForensicFace.compare (img1path:str, img2path:str)\n",
       "\n",
       "*Compares the similarity between two face images based on their embeddings.\n",
       "\n",
       "Parameters:\n",
       "    - img1path (str): Path to the first image file\n",
       "    - img2path (str): Path to the second image file\n",
       "\n",
       "Returns:\n",
       "    A float representing the similarity score between the two faces based on their embeddings.\n",
       "    The score ranges from -1.0 to 1.0, where 1.0 represents a perfect match and -1.0 represents a complete mismatch.*"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace.compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8556277"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.compare(\"obama.png\", \"obama2.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agregação de embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L525){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.aggregate_embeddings\n",
       "\n",
       ">      ForensicFace.aggregate_embeddings (embeddings, weights=None,\n",
       ">                                         method='mean')\n",
       "\n",
       "*Aggregates multiple embeddings into a single embedding.\n",
       "\n",
       "Args:\n",
       "    embeddings (numpy.ndarray): A 2D array of shape (num_embeddings, embedding_dim) containing the embeddings to be\n",
       "        aggregated.\n",
       "    weights (numpy.ndarray, optional): A 1D array of shape (num_embeddings,) containing the weights to be assigned\n",
       "        to each embedding. If not provided, all embeddings are equally weighted.\n",
       "\n",
       "    method (str, optional): choice of agregating based on the mean or median of the embeddings. Possible values are\n",
       "        'mean' and 'median'.\n",
       "\n",
       "Returns:\n",
       "    numpy.ndarray: A 1D array of shape (embedding_dim,) containing the aggregated embedding.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L525){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.aggregate_embeddings\n",
       "\n",
       ">      ForensicFace.aggregate_embeddings (embeddings, weights=None,\n",
       ">                                         method='mean')\n",
       "\n",
       "*Aggregates multiple embeddings into a single embedding.\n",
       "\n",
       "Args:\n",
       "    embeddings (numpy.ndarray): A 2D array of shape (num_embeddings, embedding_dim) containing the embeddings to be\n",
       "        aggregated.\n",
       "    weights (numpy.ndarray, optional): A 1D array of shape (num_embeddings,) containing the weights to be assigned\n",
       "        to each embedding. If not provided, all embeddings are equally weighted.\n",
       "\n",
       "    method (str, optional): choice of agregating based on the mean or median of the embeddings. Possible values are\n",
       "        'mean' and 'median'.\n",
       "\n",
       "Returns:\n",
       "    numpy.ndarray: A 1D array of shape (embedding_dim,) containing the aggregated embedding.*"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace.aggregate_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L553){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.aggregate_from_images\n",
       "\n",
       ">      ForensicFace.aggregate_from_images (list_of_image_paths, method='mean',\n",
       ">                                          quality_weight=False)\n",
       "\n",
       "*Given a list of image paths, this method returns the average embedding of all faces found in the images.\n",
       "\n",
       "Args:\n",
       "    list_of_image_paths (List[str]): List of paths to images.\n",
       "    method (str, optional): choice of agregating based on the mean or median of the embeddings. Possible values are\n",
       "        'mean' and 'median'.\n",
       "    quality_weight (boolean, optional): If True, use the FIQA(L) score as a weight for aggregation.\n",
       "\n",
       "Returns:\n",
       "    Union[np.ndarray, List]: If one or more faces are found, returns a 1D numpy array of shape (512,) representing the\n",
       "    average embedding. Otherwise, returns an empty list.*"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L553){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.aggregate_from_images\n",
       "\n",
       ">      ForensicFace.aggregate_from_images (list_of_image_paths, method='mean',\n",
       ">                                          quality_weight=False)\n",
       "\n",
       "*Given a list of image paths, this method returns the average embedding of all faces found in the images.\n",
       "\n",
       "Args:\n",
       "    list_of_image_paths (List[str]): List of paths to images.\n",
       "    method (str, optional): choice of agregating based on the mean or median of the embeddings. Possible values are\n",
       "        'mean' and 'median'.\n",
       "    quality_weight (boolean, optional): If True, use the FIQA(L) score as a weight for aggregation.\n",
       "\n",
       "Returns:\n",
       "    Union[np.ndarray, List]: If one or more faces are found, returns a 1D numpy array of shape (512,) representing the\n",
       "    average embedding. Otherwise, returns an empty list.*"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace.aggregate_from_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "set det-size: (320, 320)\n"
     ]
    }
   ],
   "source": [
    "ff = ForensicFace(extended=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated = ff.aggregate_from_images([\"obama.png\", \"obama2.png\"], quality_weight=True)\n",
    "aggregated.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extração de faces de vídeos com margem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L625){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.extract_faces\n",
       "\n",
       ">      ForensicFace.extract_faces (video_path:str, dest_folder:str=None,\n",
       ">                                  every_n_frames:int=1, margin:float=2.0,\n",
       ">                                  start_from:float=0.0,\n",
       ">                                  export_metadata:bool=False)\n",
       "\n",
       "*Extracts faces from a video and saves them as individual images.\n",
       "\n",
       "Parameters:\n",
       "    video_path (str): The path to the input video file.\n",
       "    dest_folder (str, optional): The path to the output folder. If not provided, a new folder with the same name as the input video file is created.\n",
       "    every_n_frames (int, optional): Extract faces from every n-th frame. Default is 1 (extract faces from all frames).\n",
       "    margin (float, optional): The factor by which the detected face bounding box should be extended. Default is 2.0.\n",
       "    start_from (float, optional): The time point (in seconds) after which the video frames should be processed. Default is 0.0.\n",
       "\n",
       "Returns:\n",
       "    The number of extracted faces.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| video_path | str |  | path to video file |\n",
       "| dest_folder | str | None | folder used to save extracted faces. If not provided, a new folder with the video name is created |\n",
       "| every_n_frames | int | 1 | skip some frames |\n",
       "| margin | float | 2.0 | margin to add to each face, w.r.t. detected bounding box |\n",
       "| start_from | float | 0.0 | seconds after video start to begin processing |\n",
       "| export_metadata | bool | False | if True, export facial keypoints, bounding box, ipd, fiqa_score, pitch, yaw, roll, and embedding |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L625){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.extract_faces\n",
       "\n",
       ">      ForensicFace.extract_faces (video_path:str, dest_folder:str=None,\n",
       ">                                  every_n_frames:int=1, margin:float=2.0,\n",
       ">                                  start_from:float=0.0,\n",
       ">                                  export_metadata:bool=False)\n",
       "\n",
       "*Extracts faces from a video and saves them as individual images.\n",
       "\n",
       "Parameters:\n",
       "    video_path (str): The path to the input video file.\n",
       "    dest_folder (str, optional): The path to the output folder. If not provided, a new folder with the same name as the input video file is created.\n",
       "    every_n_frames (int, optional): Extract faces from every n-th frame. Default is 1 (extract faces from all frames).\n",
       "    margin (float, optional): The factor by which the detected face bounding box should be extended. Default is 2.0.\n",
       "    start_from (float, optional): The time point (in seconds) after which the video frames should be processed. Default is 0.0.\n",
       "\n",
       "Returns:\n",
       "    The number of extracted faces.*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| video_path | str |  | path to video file |\n",
       "| dest_folder | str | None | folder used to save extracted faces. If not provided, a new folder with the video name is created |\n",
       "| every_n_frames | int | 1 | skip some frames |\n",
       "| margin | float | 2.0 | margin to add to each face, w.r.t. detected bounding box |\n",
       "| start_from | float | 0.0 | seconds after video start to begin processing |\n",
       "| export_metadata | bool | False | if True, export facial keypoints, bounding box, ipd, fiqa_score, pitch, yaw, roll, and embedding |"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace.extract_faces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "set det-size: (320, 320)\n"
     ]
    }
   ],
   "source": [
    "ff = ForensicFace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frames processed: 0/14 | Time elapsed: 00:00"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Frames processed: 14/14 | Time elapsed: 00:53\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ff.extract_faces(\n",
    "    video_path=\"/home/rafael/video/video.mp4\",\n",
    "    start_from=0,\n",
    "    every_n_frames=600,\n",
    "    dest_folder=\"/home/rafael/video_faces\",\n",
    "    export_metadata=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing aligned images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "has_sd": true,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L725){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.process_aligned_face_image\n",
       "\n",
       ">      ForensicFace.process_aligned_face_image (rgb_aligned_face:numpy.ndarray)"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/rafribeiro/forensicface/blob/main/forensicface/app.py#L725){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### ForensicFace.process_aligned_face_image\n",
       "\n",
       ">      ForensicFace.process_aligned_face_image (rgb_aligned_face:numpy.ndarray)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "#| output: asis\n",
    "show_doc(ForensicFace.process_aligned_face_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\n",
      "Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'device_id': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'cudnn_conv_use_max_workspace': '1', 'tunable_op_enable': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0'}}\n",
      "find model: /home/rafael/.insightface/models/sepaelv2/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\n",
      "set det-size: (320, 320)\n"
     ]
    }
   ],
   "source": [
    "ff = ForensicFace(extended=True, models=[\"sepaelv2\", \"sepaelv4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafael/miniconda3/envs/ffdev/lib/python3.10/site-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n"
     ]
    }
   ],
   "source": [
    "ret = ff.process_image_single_face(\"obama.png\")\n",
    "ret2 = ff.process_aligned_face_image(ret[\"aligned_face\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose(ret[\"embedding\"], ret2[\"embedding\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "language": "python"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1983922, 2.1983922)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ret[\"fiqa_score\"], ret2[\"fiqa_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
